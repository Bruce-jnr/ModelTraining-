{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":458},"executionInfo":{"elapsed":35315,"status":"error","timestamp":1756321025993,"user":{"displayName":"Bruce Jnr","userId":"02572787615479852412"},"user_tz":0},"id":"M02LFTTtzT2G"},"outputs":[{"ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3560948979.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Set this to \"gpt2\" for baseline (before SGCT), or to your fine-tuned directory for after SGCT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--\u003e 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["# ================================================\n","# Colab: Evaluate Generator (Before/After SGCT)\n","# ================================================\n","!pip install -q transformers datasets scikit-learn\n","\n","import os, json, numpy as np, pandas as pd, torch, matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","\n","# -------------------------\n","# CONFIG — edit as needed\n","# -------------------------\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","# Set this to \"gpt2\" for baseline (before SGCT), or to your fine-tuned directory for after SGCT\n","GENERATOR = \"/content/drive/MyDrive/Colab Notebooks/SGCT_final_model\"  # e.g., \"/content/sgct_gpt2_only\"\n","\n","# Your trained HPM directory (critic)\n","HPM_DIR   = \"/content/drive/MyDrive/Colab Notebooks/NewBestModel/hallucination_detector_final\"\n","\n","# Test set (JSON with at least: question, evidence, label[0/1])\n","TEST_JSON = \"/content/drive/MyDrive/Colab Notebooks/test_dataset.json\"\n","\n","# Decoding settings (use the SAME before \u0026 after for fair comparison)\n","MAX_NEW_TOKENS = 64\n","TEMPERATURE    = 0.8\n","TOP_P          = 0.9\n","\n","# HPM batching \u0026 decision threshold\n","HPM_BATCH  = 64\n","TAU        = 0.80  # threshold for calling an answer \"factual\"\n","\n","# Optional outputs\n","SAVE_DIR   = \"/content/drive/MyDrive/Colab Notebooks/eval_outputs2\"\n","SAVE_CSV   = True   # save per-example results to CSV\n","SAVE_PLOTS = True   # save confusion matrix \u0026 ROC\n","\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", DEVICE)\n","\n","# -------------------------\n","# Load models\n","# -------------------------\n","gen_tok = AutoTokenizer.from_pretrained(GENERATOR)\n","gen     = AutoModelForCausalLM.from_pretrained(GENERATOR).eval().to(DEVICE)\n","if gen_tok.pad_token is None:\n","    gen_tok.pad_token = gen_tok.eos_token\n","\n","hpm = pipeline(\"text-classification\",\n","               model=HPM_DIR,\n","               tokenizer=HPM_DIR,\n","               device=0 if DEVICE == \"cuda\" else -1)\n","\n","# -------------------------\n","# Load test data\n","# -------------------------\n","df = pd.read_json(TEST_JSON)\n","if \"label\" not in df.columns and \"labels\" in df.columns:\n","    df[\"label\"] = df[\"labels\"]\n","df[\"label\"] = df[\"label\"].astype(int)\n","df[\"question\"] = df[\"question\"].astype(str)\n","df[\"evidence\"] = df.get(\"evidence\", \"\").fillna(\"\").astype(str)\n","print(f\"Loaded test set: {len(df)} examples\")\n","\n","def make_prompt(q, e):\n","    return f\"Question: {q}\\nEvidence: {e}\\nAnswer:\" if e.strip() else f\"Question: {q}\\nAnswer:\"\n","\n","def hpm_left(q, e):\n","    return f\"Q: {q}  EVIDENCE: {e}\" if e.strip() else q\n","\n","# -------------------------\n","# Generate answers (one per item)\n","# -------------------------\n","answers = []\n","for q, e in tqdm(zip(df[\"question\"], df[\"evidence\"]), total=len(df), desc=\"Generating\"):\n","    inp = gen_tok(make_prompt(q, e), return_tensors=\"pt\").to(gen.device)\n","    with torch.no_grad():\n","        out = gen.generate(\n","            **inp,\n","            max_new_tokens=MAX_NEW_TOKENS,\n","            do_sample=True,\n","            temperature=TEMPERATURE,\n","            top_p=TOP_P,\n","            pad_token_id=gen_tok.eos_token_id,\n","        )\n","    txt = gen_tok.decode(out[0], skip_special_tokens=True)\n","    ans = txt.split(\"Answer:\")[-1].strip()\n","    answers.append(ans)\n","\n","# -------------------------\n","# Score with HPM (BATCHED)\n","# -------------------------\n","pairs = [{\"text\": hpm_left(q, e), \"text_pair\": a} for q, e, a in zip(df[\"question\"], df[\"evidence\"], answers)]\n","\n","probs = []\n","for i in tqdm(range(0, len(pairs), HPM_BATCH), desc=\"Scoring (HPM)\"):\n","    batch = pairs[i:i+HPM_BATCH]\n","    outs  = hpm(batch, batch_size=HPM_BATCH, truncation=True)\n","    for o in outs:\n","        lab = o[\"label\"]\n","        is_fact = lab in {\"FACTUAL\", \"LABEL_1\", \"factual\"}\n","        p = o[\"score\"] if is_fact else 1.0 - o[\"score\"]\n","        probs.append(float(p))\n","\n","p = np.array(probs)\n","y = df[\"label\"].values\n","yhat = (p \u003e= TAU).astype(int)\n","\n","# -------------------------\n","# Metrics\n","# -------------------------\n","print(\"\\n=== Evaluation (Before or After SGCT depending on GENERATOR) ===\")\n","try:\n","    auc = roc_auc_score(y, p)\n","    print(\"ROC-AUC:\", f\"{auc:.4f}\")\n","except ValueError:\n","    print(\"ROC-AUC: undefined (single-class labels in test set)\")\n","\n","print(\"\\nClassification Report (@TAU = {:.2f}):\".format(TAU))\n","print(classification_report(y, yhat, target_names=[\"Hallucinated (0)\", \"Factual (1)\"], digits=4))\n","\n","cm = confusion_matrix(y, yhat)\n","print(\"Confusion Matrix (@TAU = {:.2f}):\\n\".format(TAU), cm)\n","\n","factuality_at_tau = (p \u003e= TAU).mean()\n","hallucination_at_tau = (p \u003c= (1-TAU)).mean()\n","print(f\"\\nFactuality@{TAU:.2f}: {factuality_at_tau:.3f}\")\n","print(f\"Hallucination@{TAU:.2f}: {hallucination_at_tau:.3f}\")\n","\n","# -------------------------\n","# Plots\n","# -------------------------\n","if SAVE_PLOTS:\n","    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n","    ConfusionMatrixDisplay(cm, display_labels=[\"0 Halluc.\",\"1 Factual\"]).plot(ax=ax[0], colorbar=False)\n","    ax[0].set_title(f\"Confusion Matrix (@τ={TAU:.2f})\")\n","\n","    # ROC curve (skip if undefined)\n","    try:\n","        RocCurveDisplay.from_predictions(y, p, ax=ax[1])\n","        ax[1].set_title(\"ROC Curve\")\n","    except Exception:\n","        ax[1].set_visible(False)\n","\n","    plt.tight_layout()\n","    png_path = os.path.join(SAVE_DIR, \"eval_plots_sgct.png\")\n","    plt.savefig(png_path, dpi=150)\n","    plt.show()\n","    print(\"Saved plots to:\", png_path)\n","\n","# -------------------------\n","# Save per-example outputs (optional)\n","# -------------------------\n","if SAVE_CSV:\n","    out_df = df.copy()\n","    out_df[\"generated_answer\"] = answers\n","    out_df[\"p_factual\"] = p\n","    out_df[\"yhat@tau\"] = yhat\n","    csv_path = os.path.join(SAVE_DIR, \"per_example_results_sgct.csv\")\n","    out_df.to_csv(csv_path, index=False)\n","    print(\"Saved per-example results to:\", csv_path)\n","\n","# -------------------------\n","# Summary line (handy for logs)\n","# -------------------------\n","summary = {\n","    \"generator\": GENERATOR,\n","    \"n_examples\": int(len(df)),\n","    \"tau\": TAU,\n","    \"factuality_at_tau\": round(float(factuality_at_tau), 4),\n","}\n","if 'auc' in locals():\n","    summary[\"roc_auc\"] = round(float(auc), 4)\n","print(\"\\nSUMMARY:\", summary)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNRG6EdUbYhvFZfkYgO2+dy","gpuType":"T4","mount_file_id":"19PLtMEg98RZYaK3bztiIE3nHHWJSOAx1","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05e4f5fef3404e829511464554e46f9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b0841f734ac4fa5824553384bc470f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beffdbeb5f0d42c993ef6f3c8dd3d090","placeholder":"​","style":"IPY_MODEL_5db90ae929e14dff89f3d7781ae6cdc9","value":" 18/696 [00:07\u0026lt;02:32,  4.44it/s]"}},"2f7816df39c64e2ea7c9cd988d4c28b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44a94c00e0634336bb92bc327d6f4465","IPY_MODEL_adc83807157a4104bd24a9f3fdf419f4","IPY_MODEL_2b0841f734ac4fa5824553384bc470f2"],"layout":"IPY_MODEL_05e4f5fef3404e829511464554e46f9e"}},"44a94c00e0634336bb92bc327d6f4465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8efc956931244664a74cd37da32726fc","placeholder":"​","style":"IPY_MODEL_5a46ac0d5b074da080b20275127bca6f","value":"Generating:   3%"}},"5a46ac0d5b074da080b20275127bca6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5db90ae929e14dff89f3d7781ae6cdc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8efc956931244664a74cd37da32726fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f87d364ea5d4968a2a6d03b17cd57a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adc83807157a4104bd24a9f3fdf419f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f87d364ea5d4968a2a6d03b17cd57a7","max":696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcc8062ff080498aa0a88a2344380edc","value":18}},"bcc8062ff080498aa0a88a2344380edc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"beffdbeb5f0d42c993ef6f3c8dd3d090":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}